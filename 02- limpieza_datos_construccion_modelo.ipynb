{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "b35jL3fmL4HX"
      },
      "outputs": [],
      "source": [
        "#empezar a trabajar en la limpieza de los datos, identificando y completando los valores faltantes "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV1CKTfuNcoz",
        "outputId": "1500aacc-03d8-40a3-9020-8b3431be89c9"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# cargar el archivo CSV\n",
        "df = pd.read_csv('/content/newdataset.csv')"
      ],
      "metadata": {
        "id": "t3zeldA1Mfcj"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mostrar las primeras filas del dataset\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "zdh9hkBBNBx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtener información general del dataset\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "OXR_84_5NEeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtener estadísticas descriptivas del dataset\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "fC8LqOgZNGuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# identificar valores faltantes\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "X7ol2WC8NIZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtener porcentaje de valores faltantes por columna\n",
        "print(df.isnull().mean() * 100)"
      ],
      "metadata": {
        "id": "7XmvYzK8NKT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# eliminar columnas con más del 50% de valores faltantes\n",
        "umbral = 0.5\n",
        "df.dropna(thresh=umbral*len(df), axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "Rpd0tKDZNMMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# completar los valores faltantes en las columnas restantes con la media\n",
        "df.fillna(df.mean(), inplace=True)"
      ],
      "metadata": {
        "id": "vdJpPyv7NOQX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3c56d39-552f-4ad2-c9fa-c6bf8add392c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-52-d25162913ce5>:2: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  df.fillna(df.mean(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Construcción incial del modelo\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "p7iSSTc8PRtX"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar las variables dependientes e independientes\n",
        "data = pd.read_csv(\"/content/newdataset.csv\")\n",
        "X = data.drop('Application order', axis=1)\n",
        "y = data['Inflation rate']"
      ],
      "metadata": {
        "id": "WNDRCJqjZtG9"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "bkqQmgozZ56e"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Cargar datos con pandas\n",
        "data = pd.read_csv('/content/newdataset.csv')\n",
        "\n",
        "# Eliminar columnas no numéricas si es necesario\n",
        "data = data.drop('Gender', axis=1)\n",
        "\n",
        "# Cambiar el nombre de la columna\n",
        "data = data.rename(columns={'Previous qualification': 'Age at enrollment'})\n",
        "\n",
        "# Separar variables dependientes e independientes\n",
        "X = data.drop('Age at enrollment', axis=1)\n",
        "y = data['Age at enrollment']\n",
        "\n",
        "# Escalar los datos\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "P7XBbbtsZ6lH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}